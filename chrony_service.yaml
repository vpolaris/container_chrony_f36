# Generation of Kubernetes YAML is still under development!
#
# Save the output of this file and use kubectl create -f to import
# it into Kubernetes.
#
# Created with podman-3.3.1
apiVersion: v1
kind: ConfigMap
metadata:
  name: chrony-configmap
data:
  chrony.conf: |
    # from configmap
    pool time.cloudflare.com iburst maxsources 2
    pool time.google.com iburst maxsources 2
    makestep 0.1 4
    allow 0.0.0.0/0
# ---
# apiVersion: storage.k8s.io/v1
# kind: StorageClass
# metadata:
  # name: run-storage
# provisioner: kubernetes.io/no-provisioner
# volumeBindingMode: WaitForFirstConsumer
# mountOptions: #these options
  # - uid=500
  # - gid=500
  # - dir_mode=1750
# ---

# apiVersion: storage.k8s.io/v1
# kind: StorageClass
# metadata:
  # name: var-storage
# provisioner: kubernetes.io/no-provisioner
# volumeBindingMode: WaitForFirstConsumer
# mountOptions: #these options
  # - uid=500
  # - gid=500
  # - dir_mode=1750
# ---
# apiVersion: v1
# kind: PersistentVolumeClaim
# metadata:
  # # annotations:
   # # volume.beta.kubernetes.io/device: tmpfs
   # # volume.beta.kubernetes.io/driver: local
   # # volume.beta.kubernetes.io/gid: "500"
   # # volume.beta.kubernetes.io/mount-options: nodev,noexec,uid=500,gid=500,mode=1750
   # # volume.beta.kubernetes.io/type: tmpfs
   # # volume.beta.kubernetes.io/uid: "500"
  # creationTimestamp: "2022-01-03T15:54:50Z"
  # name: run-chrony
# spec:
  # storageClassName: run-storage
  # accessModes:
  # - ReadWriteOnce
  # resources:
    # requests:
      # storage: 4Ki
# status: {}
# ---
# apiVersion: v1
# kind: PersistentVolumeClaim
# metadata:
  # # annotations:
   # # volume.beta.kubernetes.io/device: tmpfs
   # # volume.beta.kubernetes.io/driver: local
   # # volume.beta.kubernetes.io/gid: "500"
   # # volume.beta.kubernetes.io/mount-options: nodev,noexec,uid=500,gid=500,mode=1750
   # # volume.beta.kubernetes.io/type: tmpfs
   # # volume.beta.kubernetes.io/uid: "500"
  # creationTimestamp: "2022-01-03T15:54:50Z"
  # name: var-chrony
# spec:
  # storageClassName: var-storage
  # accessModes:
  # - ReadWriteOnce
  # resources:
    # requests:
      # storage: 1Mi
# status: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: "2022-01-03T15:54:50Z"
  labels:
    app: chrony
  name: chrony
spec:
  selector:
    matchLabels:
      app: chrony
  # kubectl scale --replicas=x deployment/chrony-svc
  replicas: 2
  template:
    metadata:
      labels:
        app: chrony
      annotations:
        sidecar.istio.io/inject: "false"
    spec:
      containers:
      - command:
        - /bin/sh
        - -c
        - /sbin/chronyd -dUx -u chrony
        env:
        - name: PATH
          value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
        - name: TERM
          value: xterm
        - name: container
          value: podman
        - name: PLATFORM_ID
          value: platform:f33
        - name: DISTRIB_DESCRIPTION
          value: Fedora 33 Container
        - name: TZ
          value: UTC
        - name: DISTRIB_ID
          value: fedora
        - name: DISTRIB_RELEASE
          value: "33"
        - name: LANG
          value: C.UTF-8
        image: docker.io/vpolaris/chrony:4.1-1.fc33
        name: chrony
        ports:
        - containerPort: 123
          hostPort: 123
          protocol: UDP
        resources: {}
        securityContext:
          allowPrivilegeEscalation: true
          capabilities:
            drop:
            - CAP_MKNOD
            - CAP_NET_RAW
            - CAP_AUDIT_WRITE
          privileged: false
          readOnlyRootFilesystem: false
          seLinuxOptions: {}
        tty: true
        volumeMounts:
        - name: config-volume
          mountPath: /etc/chrony/chrony.conf
          subPath: chrony.conf
        # - mountPath: /var/lib/chrony
          # name: var-chrony
        # - mountPath: /run/chrony
          # name: run-chrony
        workingDir: /
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - /usr/bin/chronyc tracking || exit 1
          initialDelaySeconds: 20
          periodSeconds: 360
        readinessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - /usr/bin/chronyc tracking || exit 1
          initialDelaySeconds: 5
          periodSeconds: 10
        resources:
          requests:
            memory: "20Mi"
            cpu: "250m" # 1/4 vcpu
          limits:
            memory: "50Mi"
            cpu: "500m" # 1/2 vcpu
      dnsConfig: {}
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - chrony
            topologyKey: "kubernetes.io/hostname"
      securityContext:
        # runAsUser: 500
        # runAsGroup: 500
        # fsGroup: 500
      volumes:
      - name: config-volume
        configMap:
          name: chrony-configmap
      # - name: var-chrony
        # emptyDir:
          # medium: Memory
          # sizeLimit: 1Mi
      # - name: run-chrony
        # emptyDir:
          # medium: Memory
          # sizeLimit: 8Ki
      # - name: var-chrony-pvc
        # persistentVolumeClaim:
          # claimName: var-chrony
      # - name: run-chrony-pvc
        # persistentVolumeClaim:
          # claimName: run-chrony
---
apiVersion: v1
kind: Service
metadata:
  name: chrony-service
  #namespace: default
  labels:
    app: chrony
spec:
  ports:
  # port=available to other containers
  - port: 123
    name: ntp
    # targetPort=exposed from inside container
    targetPort: 123
    protocol: UDP
  selector:
    app: chrony
